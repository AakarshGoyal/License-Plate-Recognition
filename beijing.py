# -*- coding: utf-8 -*-
"""Plate detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hoSWR8wVUKdQ78XcPnBvnrm_ho7Y0tA5
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

def PlateDetect(img,net,classes):
    # net =cv2.dnn.readNet('/content/gdrive/MyDrive/PS2_Mosaic/YOLO/backup/darknet-yolov3_last.weights','/content/gdrive/MyDrive/PS2_Mosaic/YOLO/darknet-yolov3.cfg')
    # classes=[]
    # with open('/content/gdrive/MyDrive/PS2_Mosaic/YOLO/classes.names','r') as f:
    #     classes=f.read().splitlines()

    # for classi in classes:
    #     print(classi)
    # cap=cv2.VideoCapture(0)

    if img is None:
        print("No Image Found")
        return None
    height,width,_= img.shape
    blob=cv2.dnn.blobFromImage(img,1/255,(416,416),(0,0,0),swapRB=True,crop=False)
    net.setInput(blob)
    output_layer_names=net.getUnconnectedOutLayersNames()
    layerOutputs =net.forward(output_layer_names)
    # while True:
    #     ret,img = cap.read()
    #     height,width,_= img.shape
    #     blob=cv2.dnn.blobFromImage(img,1/255,(416,416),(0,0,0),swapRB=True,crop=False)
    #     net.setInput(blob)
    #     output_layer_names=net.getUnconnectedOutLayersNames()
    #     layerOutputs =net.forward(output_layer_names)
        
    boxes=[]
    confidences=[]
    class_ids=[]
        
    for output in layerOutputs:
        for detection in output:
            scores=detection[5:]
            class_id=np.argmax(scores)
            confidence=scores[class_id]
            if confidence>.6 :
                centre_x=int(detection[0]*width)
                centre_y=int(detection[1]*height)
                w=int(detection[2]*width)
                h=int(detection[3]*height)
                x=int(centre_x-w/2)
                y=int(centre_y-h/2)
                boxes.append([x,y,w,h])
                confidences.append((float(confidence)))
                class_ids.append(class_id)
                    
    indexes=cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)
    if not confidences:
        print("nothing here")
        return 0,img
    confi=max(confidences)
    print(confi)
    indexes1 = np.asarray(indexes)
    font=cv2.FONT_HERSHEY_PLAIN
    colors= np.random.uniform( 0, 255, size = ( len( boxes ),3))

    for i in indexes1.flatten():
      if confi==confidences[i]:
        x, y, w, h = boxes[i]
        label=str(classes[class_ids[i]])
        confidence=str(round(confidences[i],2))
        color=colors[i]
        img2=img.copy()[y:y+h,x:x+w]
        cv2_imshow(img2)
        cv2.rectangle(img,(x,y),(x+w,y+h),color,2)
        cv2.putText(img,label+" "+ confidence,(x,y+20),font,2,(255,255,255),2)

    cv2_imshow(img)
    cv2.waitKey(0)
   


    cv2.destroyAllWindows()
    return confi,img2















